

Nachdem wir zuvor einen groben Überblick über die Entwicklung und die wichtigsten Aspekte des EU AI Acts gegeben haben, möchten wir nun einen genaueren Blick auf das Herzstück des EU AI Acts werfen: die Einteilung der Risikostufen. In diesem Abschnitt wird erläutert, welche Risikostufen es gibt, welche Systeme in welche Kategorie fallen und welche Anforderungen daraus für Organisationen entstehen. Sobald Sie ein grundlegendes Verständnis der Risikostufen erlangt haben, werden wir im zweiten Schritt zwei praktische Beispiele für die Einordnung von Systemen in die verschiedenen Risikostufen betrachten und Ihnen ein Tool vorstellen, das Sie selbst zur Einstufung nutzen können.

Für eine einfache Übersicht über die verschiedenen Risikostufen, schauen Sie sich gerne folgendes Video an:

EINBETTUNG VIDEO


Nachdem Sie sich nun mit den Grundlagen der Risikostufen vertraut machen konnten, können wir uns nun den Beispielen zuwenden, die praktischen Herausforderungen besser illustrieren.

**Beispiel 1 - AntragsAssistent**

Stellen Sie sich vor Sie sind Teil einer kleinen in Berlin ansässigen Organisation, die es sich zum Ziel gesetzt hat Personen aus benachteiligten Gruppen bei der Kommunikation mit Behörden zu unterstützen bspw. durch Hilfe beim Schreiben von Briefen oder Anträgen, kleiner Übersetzungsleistungen o.Ä.. Um Ihre Prozesse zu optimieren haben Sie vor ein Unterstützungstool einzukaufen, dass die Unterlagenprüfung für Sie übernimmt. Personen die zu Ihnen kommen können dort ihre Dokumente digital hinterlegen, diese werden dann vom Antrags Assistenten geprüft, der Ihnen und ihren Kolleg:innen eine Auskunft darüber gibt, wie das System die Chancen auf Erfolg bei Antragsstellung bewertet. Das System kann keine Personen ablehnen und keine eigenständigen Entscheidungen treffen. Was glauben Sie? Nehmen Sie sich einen Moment Zeit und denken Sie darüber nach wo ein solches System eingeordnet werden könnte. Wir fassen die wichtigsten Informationen hier noch mal zusammen, dabei spielen nicht nur die Dinge eine Rolle, die das System tut, sondern explizit auch was es nicht tut oder kann.

Übersicht Beispielsystem 1 - AntragsAssistent

- Unsere Organisation setzt das System nur ein.
- Wir sind mit unserem Standort in Berlin innerhalb der EU niedergelassen.
- Wir nutzen das System weder für militärische Zwecke, noch sind wir Teil einer Behörde oder Forschungseinrichtung.
- Das System wird nicht für Dinge wie Social Scoring, Emotionserkennung oder Verhaltensmanipulation genutzt.
- Da es sich um ein System handelt, dass potenziell den Zugang zu privaten und öffentlichen Leistungen beeinflusst, könnte dies besondere Auswirkungen auf die Einstufung unseres Tools haben. Wichtig ist dabei vor allem, dass kein erhebliches Risiko für die Gesundheit, die Sicherheit oder die Grundrechte einer Person darstellt.

Prüfen wir basierend auf diesen Informationen unser Assistenzsystem so bedeutet das, dass die Anwendung mit hoher Wahrscheinlichkeit der niedrigsten Risikostufe zugeordnet wird. Für Sie als Nutzende heißt das, dass Sie das System wie geplant nutzen können. Auf Anbieterseite ist dies allerdings mit einigen Pflichten verbunden. So muss das System in einer EU-Datenbank registriert werden und die getätigten Anfragen müssen beim Anbieter so gesichert werden, dass dieser Sie auf Anfrage der EU-Behörden übertragen kann.


**Beispiel 2**

Für unser zweites Beispiel stellen wir uns vor wir sind Teil einer in den USA und Europa agierenden auf Nachhaltigkeit und Tierwohl ausgerichtetet Organisation, die in Kooperation mit einer ländlichen Kommune die Population in einem Waldstück überwachen und messen möchte. Um ein möglichst detailliertes Bild zu bekommen sendet Ihnen ihre Hauptstelle in den Staate durch KI-Erkennungssystem gesteuerte Kameras, die im Waldstück angebracht werden und automatisch Tiere bedrohter Arten identifizieren und die gemachten Bilder speichern sollen. Bei der genutzten Tiererkennungssoftware handelt es sich um eine etablierte Anwendung eines großen Technologiehauses, die in Kooperation mit ihrer Hauptstelle entwickelt und in den USA schon weiträumig mit erfolg eingesetzt wird. Aufgrund der Serverinfrastruktur auf die das System zurückgreift werden Daten, die in Deutschland aufgenommen werden in der Hauptstelle in den USA verarbeitet und aufgenommen.

Nehmen Sie sich auch hier wieder einen Moment Zeit und denken Sie darüber nach welcher Risikostufe so ein System zugeordnet werden könnte. Hier noch einmal die wichtigsten Informationen:

- Das System wird von unserer Organisation hergestellt und eingesetzt.
- Wir sind eine amerikanische Organisation mit einem Standort in Deutschland.
- Wir nutzen das System weder für militärische Zwecke, noch sind wir Teil einer Behörde oder Forschungseinrichtung.
- Das System wird nicht für Dinge wie Social Scoring, Emotionserkennung oder Verhaltensmanipulation genutzt.
- Das System wird nicht in einem Hochrisikobereich eingesetzt bspw. bei der Strafverfolgung oder zum Grenzkontrollmanagement.


Prüfen wir basierend auf diesen Informationen unser Assistenzsystem so bedeutet das, dass auch diese Anwendung mit hoher Wahrscheinlichkeit der niedrigsten Risikostufe zugeordnet wird. Trotz der Verarbeitung der Daten im Nicht-Eu-Ausland und dem Einsatzgebiet bei der Überwachung handelt es sich mit hoher Wahrscheinlichkeit um ein System, dass auf Nutzendenseite keine weiteren Pflichten mit sich bringt. Unsere Dachorganisation bzw. der Technologiekonzern unterliegen dabei trotz ihres Standortes in den USA den gleichen Transparenzpflichten wie in Beispiel 1, wenn sie ihr System innerhalb der EU einsetzen wollen.


Die genaue Einschätzung in welche Risikostufe ein gegebenes KI-System fällt kann durchaus komplex sein und hängt von mehr Faktoren ab als wofür es inhaltlich genutzt wird bspw. ob ich als Hersteller und Nutzender auftrete. Wo ich das System einsetzen will? Ob ich Teil der EU bin etc. Um sich einen Überblick über die verschiedenen Möglichkeiten zu verschaffen gibt es den EU Compliance Checker. Das Tool bietet die Möglichkeit verschiedene Varianten durchzuspielen, um herauszufinden welche Regelungen für das eigene System gelten. Wir empfehlen daher es einmal selbst auszuprobieren und die oben genannten Beispiele oder eigene Idee einfach mal auf https://artificialintelligenceact.eu/de/bewertung/eu-ai-act-compliance-checker/ auszuprobieren.

Im nächsten Abschnitt gehen wir dann noch mal konkret auf die Auswirkungen der Risikostufen auf mögliche Entwicklungsprozesse ein.

