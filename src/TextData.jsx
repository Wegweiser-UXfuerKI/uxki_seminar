/*
"## Text"" = Title
"Text" = Text
"##list Text ##list Text" = Liste mit zwei Texten
*/
export const TextData = {
    Einleitung: {
        VideoLink: {
            link: "https://www.youtube-nocookie.com/embed/kxsbAi3gmeE?si=PL74OEuieI7W2hce&amp;rel=0&amp;modestbranding=1", title: "Einleitungsvideo"},
        Texte: [
            { title: "EU AI Act", texts: [
                "Nachdem Sie nun ein kurzes Einführungsvideo gesehen haben, wenden wir uns nun einer etwas detaillierteren Betrachtung des EU AI Acts zu.",
                "## Ziele des EU AI Acts",
                "Mit dem EU AI Act haben sich die Mitgliedsstaaten der EU zum Ziel gesetzt, das erste umfassende Regularium für den Umgang mit Systemen, die auf Künstlicher Intelligenz (KI) basieren, zu verfassen. Ziel ist es, rechtliche Rahmenbedingungen zu schaffen, in denen KI-Projekte in Wirtschaft, Forschung und Gesellschaft so eingesetzt und entwickelt werden können, dass ein vertrauenswürdiger Umgang mit den Systemen möglich ist. Die fundamentalen Rechte der Nutzer:innen, aber auch Aspekte wie Sicherheit und das Handeln auf Grundlage ethischer Prinzipien, sollen dabei mit einbezogen werden. Dabei soll der EU AI Act über die Grenzen der EU hinaus einen Impuls setzen und, ähnlich wie die DSGVO im Datenschutz, einen Standard stellen, der auch in Nicht-EU-Ländern wie den USA oder Japan genutzt wird.",
                "",
                "## Entwickluing des Acts",
                "Bei der Entwicklung des EU AI Acts handelt es sich um einen komplexen bürokratischen Prozess, der sich nicht nur über viel Jahre hinweg entwickelte, sondern auch große Teile des parlamentarischen EU-Apparats durchlaufen hat.",
                "##list Der erste Schritt dieses Prozesses war 2021 ein erster Vorschlag zur Regulierung von künstlicher Intelligenz durch die EU-Kommission. ##list Im November 2021 entstand ein erster Kompromisstext, der u.a. gesamtgesellschaftlich relevante Anwendungsfälle wie Social-Scoring-Systeme oder biometrische Erkennungssysteme beinhaltet bzw. diese verbieten soll. ##list Im Jahr 2022 wurde dieser Kompromisstext in den Gremien diskutiert und  Stück für Stück erweitert und ausgearbeitet. So kamen das Thema der Transparenzpflicht (Februar) oder die Regulierung von Systemen mit allgemeinen Verwendungszwecken (Mai) nach und nach hinzu. Auch Fragen der Haftbarkeit und der Durchsetzung von Schadensansprüchen wurden in dieser Zeit diskutiert. ##list Am 1. Juni 2022 endete die Frist für die Fraktionen des EU-Parlamentes für die Einreichung von Änderungsanträgen des EU AI Gesetzes. Insgesamt wurden mehrere Tausend Anträge und Änderungen eingereicht, die in die Ausarbeitung des finalen Textes einbezogen wurden. ##list Am 14. Juni 2023 kam es dann zur großen Abstimmung im EU-Parlament. Mit 499 Ja-Stimmen, 28 Nein-Stimmen und 93 Enthaltungen wurde eine Verhandlungsposition zum AI-Gesetz angenommen. ##list Am 09. Dezember 2023 erzielten Rat und Parlament dann eine vorläufige Einigung zum AI-Gesetz. ##list Mit Beginn des Jahres 2024 wurde das Europäische Büro für künstliche Intelligenz innerhalb der Kommission eingerichtet und weitere Prozesse für die schrittweise Umsetzung und Ausgestaltung des EU AI Acts angestoßen. Ein vollständige Übersicht des zeitlichen Verlaufs des Gestaltungsprozesses und der damit verbundenen Institutionen und Zwischenstände finden Sie hier: [https://artificialintelligenceact.eu/de/entwicklungen/](https://artificialintelligenceact.eu/de/entwicklungen/).",
                "",
                "## Vergleich mit anderen Ländern / Regionen",
                "## insbesondere USA, Kanada und England",
                "Betrachtet man den EU AI Act als groß angelegte Normierung innerhalb des europäischen Raums, drängt sich schnell die Frage auf, welche Auswirkungen die Gesetzgebung außerhalb seiner Mitgliedsstaaten haben wird. Es kann dabei davon ausgegangen werden, dass das EU-Parlament zwar primär die Regulierung im eigenen Legislaturbereich im Blick hat, aber auch auf andere große Volkswirtschaften wie die USA, China und das Vereinigte Königreich schaut, wenn es um den Einsatz von KI geht. Wie schon bei der Datenschutz-Grundverordnung (DSGVO) scheint hier der Gedanke zu sein, einen weitreichenden \"Goldstandard\" zu schaffen, der auch die Gesetzgebung in den Nationen außerhalb der EU bestimmt. Wir halten es deshalb für sinnvoll, einen kurzen Blick auf den aktuellen Stand der KI-Regulierung in anderen Nationen zu werfen, um diese Vorstellung besser einordnen zu können.",
                "### Vereinigtes Königreich",
                "Schaut man dazu beispielsweise über den Kanal ins Vereinigte Königreich, so stellt man fest, dass auch dort weitreichende Maßnahmen für die Regulierung und den ethischen Umgang mit KI bereits getroffen worden sind. Die britische Regierung setzt dabei auf bestehende sektorale Vorgaben wie bspw. die KI-Prinzipien der OECD oder die Empfehlung zu ethischem Umgang mit KI der UNESCO. Diese übergeordneten Richtlinien werden durch lokal angetriebene Maßnahmen erweitert. Von besonderer Bedeutung ist dabei zum Beispiel die Bletchley Declaration aus November 2023, bei der sich 28 Länder, darunter die Vereinigten Staaten, China und die Europäische Union, geeinigt haben, international bei der Bewältigung von Herausforderungen und Risiken im Bereich der KI zusammenzuarbeiten. Im Fokus standen dabei vor allem \"frontier\"-Systeme, also KI-Grundlagenmodelle, die für alle möglichen Anwendungsfälle nutzbar gemacht werden können, so wie bspw. die ChatGPT zugrundeliegenden LLMs.  Es gibt also ein klares Bewusstsein für die Bedeutung des Themas KI und erste Bestrebungen für Lösungen. Die dabei getroffenen Vereinbarungen sind dabei eher Leitlinie und weniger strenges Regularium als es der EU AI Act sein möchte.",
                "### USA",
                "Demgegenüber steht die Regulierung von KI in den USA derzeit noch am Anfang. Zwar sind auch diese Teil der Bletchley Declaration, trotzdem fehlt ein kohärentes nationales Regelwerk. Aktuell gibt es in den USA keine umfassende föderale KI-Regulierung, sondern lediglich fragmentierte Richtlinien und Bestrebungen auf Bundesstaatenebene und in verschiedenen Sektoren. Bundesbehörden wie die Federal Trade Commission (FTC) haben zwar Leitlinien zur Vermeidung unfairer oder irreführender KI-Anwendungen herausgegeben, aber umfassende gesetzliche Regelungen stehen noch aus.",
                "Allerdings gibt es zunehmend Bestrebungen, eine konsistente Regulierung zu entwickeln. Präsident Joe Biden hat Anfang 2021 den \"National Artificial Intelligence Initiative Act\" unterzeichnet, der die Forschung und Entwicklung von KI koordiniert und fördert. Zudem hat das Weiße Haus Ende 2022 einen \"Blueprint for an AI Bill of Rights\" veröffentlicht, der Prinzipien zum Schutz der Bürgerrechte im Zusammenhang mit KI vorschlägt.",
                "Während die EU mit dem AI Act einen klaren und strengen Regulierungsrahmen vorgibt, arbeiten die USA daran, ihre Strategie zu entwickeln, die wahrscheinlich stärker auf Selbstregulierung und sektorale Ansätze setzt, um Innovationen nicht zu behindern ([Pinsent Masons](https://www.pinsentmasons.com/out-law/news/eu-ai-act-takes-latest-step-through-european-parliament)) ([Skadden, Arps, Slate, Meagher & Flom LLP](https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation)).",
                "### Kanada",
                "Im Kontext des EU AI Acts hat Kanada ebenfalls Schritte unternommen, um den Einsatz von KI zu regulieren und zu fördern. Aktuell wird KI in Kanada hauptsächlich durch den **Artificial Intelligence and Data Act (AIDA)** reguliert, der Teil des umfassenden Digital Charter Implementation Acts ist, welcher im Juni 2022 vorgeschlagen wurde. AIDA zielt darauf ab, KI-Systeme zu regulieren, die ein erhebliches Risiko für die Sicherheit der Menschen oder ihre Grundrechte darstellen. Der Ansatz umfasst Verpflichtungen zur Transparenz, zur Risikobewertung und zur Einhaltung ethischer Standards.",
                "Zusätzlich gibt es in Kanada Bestrebungen, die Regulierung weiter zu verfeinern und zu stärken. Die kanadische Regierung arbeitet daran, Richtlinien und Standards zu entwickeln, die sicherstellen, dass KI-Systeme sicher, fair und transparent sind. Dies beinhaltet auch die Zusammenarbeit mit internationalen Partnern und Organisationen, um globale Standards zu fördern und die Interoperabilität von Regulierungsrahmen zu gewährleisten.",
                "Im Vergleich zum EU AI Act, der einen sehr strukturierten und strengen Rahmen vorgibt, verfolgt Kanada einen eher kooperativen und flexiblen Ansatz. Die kanadische Regulierung konzentriert sich auf die Förderung von Innovationen, während sie gleichzeitig sicherstellt, dass die Entwicklung und der Einsatz von KI ethisch und verantwortungsvoll erfolgen ([Pinsent Masons](https://www.pinsentmasons.com/out-law/news/eu-ai-act-takes-latest-step-through-european-parliament))​​ ([Skadden, Arps, Slate, Meagher & Flom LLP](https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation))​.",
                "Zusammengefasst kann festgehalten werden, dass zwar viele Nicht-EU-Nationen eine klare Vorstellung von KI und potenziellen unkontrollierten Auswirkungen haben, im Gegensatz zur EU allerdings teilweise noch am Anfang einer konkreten Ausformulierung von Regeln und Gesetzen stehen oder generell einen offeneren Ansatz mit Blick auf möglichst freie Innovationsentwicklung verfolgen.",
                "## Umsetzung des Acts in den Mitgliedstaaten",
                "Die faktische Umsetzung des EU AI Acts in den Mitgliedstaaten erfordert sorgfältige Planung und Koordination, um die umfassenden Anforderungen des Gesetzes zu erfüllen.",
                "## Primäre Inhalte des Eu AI Acts",
                "Der EU AI Act ist ein umfassendes Regelwerk, das den Einsatz von KI innerhalb der EU reguliert. Zu den primären Inhalten gehören die Kategorisierung von KI-Systemen nach ihrem Risiko (unzulässiges, hohes, begrenztes und minimales Risiko), spezifische Anforderungen für Hochrisiko-Systeme, Transparenz- und Sicherheitsanforderungen sowie die Einrichtung eines EU-weiten Überwachungssystems für KI-Anwendungen. Einen tieferen Einblick in das Thema Risikoklassifizierung und Risikostufen finden Sie in den Kapiteln 02 und 03. Diese Maßnahmen zielen darauf ab, die Sicherheit, Transparenz und Verantwortung im Umgang mit KI zu gewährleisten und gleichzeitig Innovationen zu fördern. Darüber hinaus bilden sie eine feste rechtliche Grundlage, die Unternehmen, Forschung und Endnutzer:innen befähigt, rechtssicher mit KI umzugehen.",
                "### Anwendungsbereich und betroffene Systeme",
                "Der Act findet Anwendung bei verschiedenen KI-Systemen, abhängig von ihrem Risiko. Hochrisiko-Systeme umfassen beispielsweise KI-Anwendungen in kritischen Infrastrukturen, wie etwa KI-gesteuerte Systeme im Gesundheitswesen. Ein konkretes Beispiel wäre ein KI-gestütztes Diagnosetool in Krankenhäusern, das strengen Auflagen hinsichtlich Datenqualität, Transparenz und menschlicher Aufsicht unterliegt. Niedrigrisiko-Systeme, wie etwa Chatbots oder KI-basierte Spiele, unterliegen weniger strengen Regelungen, müssen aber dennoch gewisse Transparenzanforderungen erfüllen.",
                "### Relevante Beteiligte",
                "Alle Anbieter:innen und Nutzer:innen von KI-Systemen innerhalb der EU müssen sich mit den Anforderungen des Acts auseinandersetzen. Dies umfasst Entwickler:innen, Anbieter:innen und Anwender:innen von KI-Technologien. Privatpersonen, die KI-Anwendungen wie ChatGPT nutzen, sind in der Regel nicht direkt betroffen, solange sie diese nur als Endnutzer:innen einsetzen und die Anwendungen den regulatorischen Anforderungen entsprechen. Unternehmen, die solche Technologien entwickeln oder bereitstellen, müssen hingegen sicherstellen, dass ihre Produkte konform sind.",
                "### Sanktionen bei Verstößen",
                "Bei Verstößen gegen den EU AI Act drohen erhebliche Sanktionen. Die vorgeschlagenen Strafen umfassen Bußgelder von bis zu 35 Millionen Euro oder 7% des weltweiten Jahresumsatzes. Die faktische Umsetzung des EU AI Acts in den Mitgliedstaaten erfordert umfassende Maßnahmen zur Einhaltung der neuen Vorschriften, die eine sichere und transparente Nutzung von KI sicherstellen sollen.",
                "## Fazit",
                "Zusammenfassend lässt sich sagen, dass der EU AI Act ein umfassendes und wegweisendes Regelwerk darstellt, das den Einsatz von KI in der EU regulieren soll. Er kategorisiert KI-Systeme nach ihrem Risikoniveau und legt spezifische Anforderungen für Hochrisiko-Systeme fest, um Sicherheit, Transparenz und Verantwortlichkeit zu gewährleisten. Der Act betrifft eine Vielzahl von KI-Anwendungen, von Gesundheitsdiagnosetools bis hin zu Chatbots, und erfordert von Anbieter:innen und Nutzer:innen die Einhaltung strenger Vorgaben. Bei Verstößen drohen erhebliche Sanktionen, einschließlich hoher Bußgelder. In den nächsten Modulen werden wir uns detailliert mit den Risikostufen und der Klassifizierung von KI-Systemen befassen, um ein tieferes Verständnis für die Implementierung und Einhaltung des EU AI Acts zu entwickeln.",
            ]}
        ]
    },
    Risikostufen: {
        VideoLink: {
            link: "https://www.youtube-nocookie.com/embed/zkfqjX6om8g?si=XKEX_r1jRmViUJkB&amp;rel=0&amp;modestbranding=1", title: "Video",
        },
        Texte: [
            { title: "Wie funktionieren Risikostufen", texts: [
                "Wie zuvor besprochen wollen wir uns als erstes mit dem Thema Risikostufen beschäftigen. Zentral ist dabei das Verständnis, dass nicht jedes KI-System gleich viel Einfluss auf uns als Menschen hat - bei manchen sind die Risiken höher als bei anderen. Manchmal sogar inakzeptabel hoch. Die Notwendigkeit einer solchen Unterteilung hat auch die EU erkannt und deswegen ein zentrales Werkzeug im EU AI Act erschaffen - die Einteilung von KI-Systemen in vier Risikostufen:",
                "Die niedrigste Stufe geht davon aus, dass durch ein KI-System nur ein minimales Risiko besteht. Beispiele hierfür sind KI-Systeme, die in Videospielen eingesetzt werden oder intelligente Spam-Filter, die bestenfalls nach festen Regeln vorgehen.",
                "Die zweite Stufe kategorisiert Systeme mit einem begrenzten Risiko s.g. limited risk. Bei diesen gelten insbesondere Transparenzvorschriften, d.h., es muss klar gemacht werden, dass KI Systeme eingesetzt werden und wie. Das gilt z.B. beim Einsatz von Chatbots.",
                "Das Herzstück des Acts stellen final die High-Risk-Systeme da. Hierzu zählen alle Systeme, die irgendeiner Zulassung bedürfen. Dazu gehören medizinische Systeme, Systeme im Bereich der Strafverfolgung oder auch Systeme, die zur politischen Meinungsbildung geeignet sind. Der EU AI Act formuliert in dieser Kategorie hohe Anforderungen in Bezug auf die verschiedenen genutzten Variablen. So beispielsweise für die Dokumentation des Trainings, des genutzten Models und der bei der Entwicklung getroffenen Designentscheidungen. Für uns ist dabei vor allem der Punkt Transparenz und die Möglichkeit, der menschlichen Kontrollfähigkeit interessant."
            ]},
            { title: "Zu beachten bei Risikostufen", texts: [
                "Letztlich gibt es noch Systeme mit einem inakzetabel hohen Risiko. Darunter fallen alle Systeme, die für Menschen und unsere demokratischen Werte gefährlich sein können bspw. Social Scoring Systeme, Deep Fake Tools oder Profiling systeme. Alle Systeme, die in diese Kategorien fallen, sind vollständig verboten. Generell steht noch nicht fest, wie viele Systeme am Ende im Bereich high risk landen werden, aber wir gehen derzeit davon aus, dass es zwischen 15-30% sein könnten. Insbesondere gemeinwohlorienterte KI kann zudem das ziel haben, allen Anforderungen gerecht zu werden - egal ob high risk oder nicht.",
                "Ein letzter Hinweis noch: sehr mächtige KI-Modelle, die man für viele Zwecke einsetzen kann, nennt die Verordnung \"General Purpose AI\". Dazu gehören so Systeme wie große Sprachmodelle, die hinter ChatGPT stecken. Diese Systeme gehören nicht explizit einer Risikostufe an, haben aber nochmal ganz eigene Regeln, die in einem gesonderten Kapitel des EU AI Acts festgehalten sind.",
            ]},
        ]
    },
    Designimplikationen: {
        VideoLink: {
            link: "https://www.youtube-nocookie.com/embed/0rPt4Grl8D4?si=2BKL-W0acY6LRGPu&rel=0&modestbranding=1", title: "Video",
        },
        Texte: [
            { title: "Weitergehende Kriterien", texts: [
                'Nachdem wir uns nun damit beschäftigt haben was der EU AI Act eigentlich ist und wie er versucht durch Risikostufen die Nutzung von verschiedenen Arten von KI Systemen zu regulieren, wollen wir uns jetzt einmal angucken was diese Regeln jetzt für die Gestaltung bedeuten. Schauen wir uns das mal an ein paar Beispielen an! Als erstes greifen wir unseren Telefon-Seelsorge Chatbot auf. Egal ob er am Ende in einem Kontext mit hohem Risiko oder nicht eingesetzt wird, es MUSS klar gemacht werden, dass hier kein Mensch agiert. Insofern sollte man z.B. nicht "schreibt" als Animation einsetzen, wenn der Bot antwortet. Das wäre täuschend und deutet auf einen wirklichen Menschen hin. Eine Alternative wäre der Einsatz von eher technischen Begriffen wie "Antwort wird berechnet", die auf die maschinelle Natur des Gesprächspartners hinweisen. Auch bei einer gegebenen Antwort sollte der Chatbot seine Grenzen verdeutlichen, z.B. indem er markiert, welche Absichten (Intent) er erkannt hat. Zusätzlich muss die menschliche Kontrollfähigkeit hoch genug sein - Mitarbeitende der Telefonseelsorge müssen den Chatbot (leicht) anpassen können. Es muss ein Interface geben, um z.B. die Länge der Antworten zu steuern oder wann der Chatbot an menschliche Agenten weitergibt so, dass er möglichst einfach und barrierefrei in der praktischen Alltagsnutzung ist. Greifen wir uns als zweites Beispiel den Algorithmus zur Detektion von Hassnachrichten. Bei einer solchen Anwendung geht es uns vor allem darum, zu prüfen, ob er so arbeitet, wie von uns gewünscht. Daher sollten wir bei der Gestaltung daran denken, dass er nachvollziehbare Erklärungen über sein trainiertes Modell abgeben kann. Eine Möglichkeit wären die von uns erklärten Shapley Values aus dem Modul X. *Hier nochmal ein Beispiel.* Nutzende können dann die Visualisierung aufrufen und für eine bestimmte Nachricht erkennen, weshalb diese als Hatespeech klassifiziert wird. alternativ kann man aber auch über so genannte *counterfactual explanation* arbeiten. Bei diesen kann die nutzende Person sich anzeigen lassen, durch welche Wortänderungen das System NICHT mehr von *hate speech* ausgehen würde. Hier ist jedoch Vorsicht geboten - die Systeme können so vielleicht leichter ausgetrickst werden, weil man genau sehen kann, wie sie funktionieren. Es ist also eine Gewissensentscheidung wie transparent die Antworten des Systems für die Nutzenden sein sollen. Unser letztes Beispiel beschäftigt sich mit der Empfehlung von Nahrungsmitteln. Bei einem solchen System ist es unser Ziel zu verhindern, dass Menschen von Handlungen/ Empfehlungen überzeugt werden, die sie selbst nicht wollten oder gutheißen. Daher sollten wir explizit zeigen, weshalb ein Vorschlag für ein spezifisches Lebensmittel gegeben wird, z.B. das stärkste Feature wie (Beispiel) für einen Vorschlag hervorheben. Eine weiter Möglichkeit, um ungewollte Beeinflussung der Nutzenden zu verhindern ist es die Distanz zwischen präsentierten Vorschlägen zu kommunizieren bspw. wenn sich zwei Produkte, die durch das System auf verschiedene Plätze eingeordnet worden sind eigentlich nur sehr geringfügig unterscheiden. Mit diesen Anwendungsbeispielen im Kopf, was bedeutet das für Sie? Welche Designentscheidungen müssen sie treffen so, dass ihr System nicht nur konform mit dem EU AI ACT ist, sondern auch die Bedürfnisse der Nutzenden in den Mittelpunkt stellt.',
            ]}
        ]
      },
      Fazit: {
        VideoLink: {
            link: "https://www.youtube-nocookie.com/embed/PZAkt-EuKn0?si=g-hnbptFXBW6kajx&amp;rel=0&amp;modestbranding=1", title: "Video",
        },
        Texte: [
            { title: "Diskussion", texts: [
                "Lorem ipsum, dolor sit amet consectetur adipisicing elit. Quos temporibus itaque sit ipsa ex reiciendis, sint earum hic aliquid vel atque enim, inventore, magni numquam commodi iste? Quam, ab iure. Lorem ipsum dolor sit amet consectetur adipisicing elit. Consequatur odit aut impedit facilis laboriosam, adipisci eaque eos incidunt ad tenetur debitis repudiandae eius non recusandae. Quo harum at nostrum veritatis.",
            ]}
        ]
      },
}