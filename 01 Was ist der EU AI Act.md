Nachdem Sie nun ein kurzes Einführungsvideo gesehen haben, wenden wir uns nun einer etwas detaillierteren Betrachtung des EU AI Acts zu.

## *Ziele des EU AI Acts*

Mit dem EU AI Act haben sich die Mitgliedsstaaten der EU zum Ziel gesetzt, das erste umfassende Regularium für den Umgang mit Systemen, die auf Künstlicher Intelligenz (KI) basieren, zu verfassen. Ziel ist es, rechtliche Rahmenbedingungen zu schaffen, in denen KI-Projekte in Wirtschaft, Forschung und Gesellschaft so eingesetzt und entwickelt werden können, dass ein vertrauenswürdiger Umgang mit den Systemen möglich ist. Die fundamentalen Rechte der Nutzer:innen, aber auch Aspekte wie Sicherheit und das Handeln auf Grundlage ethischer Prinzipien, sollen dabei mit einbezogen werden. Dabei soll der EU AI Act über die Grenzen der EU hinaus einen Impuls setzen und, ähnlich wie die DSGVO im Datenschutz, einen Standard stellen, der auch in Nicht-EU-Ländern wie den USA oder Japan genutzt wird.

## *Entwicklung des Acts*

Bei der Entwicklung des EU AI Acts handelt es sich um einen komplexen bürokratischen Prozess, der sich nicht nur über viel Jahre hinweg entwickelte, sondern auch große Teile des parlamentarischen EU-Apparats durchlaufen hat.

- Der erste Schritt dieses Prozesses war 2021 ein erster Vorschlag zur Regulierung von künstlicher Intelligenz durch die EU-Kommission.
- Im November 2021 entstand ein erster Kompromisstext, der u.a. gesamtgesellschaftlich relevante Anwendungsfälle wie Social-Scoring-Systeme oder biometrische Erkennungssysteme beinhaltet bzw. diese verbieten soll.
- Im Jahr 2022 wurde dieser Kompromisstext in den Gremien diskutiert und  Stück für Stück erweitert und ausgearbeitet. So kamen das Thema der Transparenzpflicht (Februar) oder die Regulierung von Systemen mit allgemeinen Verwendungszwecken (Mai) nach und nach hinzu. Auch Fragen der Haftbarkeit und der Durchsetzung von Schadensansprüchen wurden in dieser Zeit diskutiert.
- Am 1. Juni 2022 endete die Frist für die Fraktionen des EU-Parlamentes für die Einreichung von Änderungsanträgen des EU AI Gesetzes. Insgesamt wurden mehrere Tausend Anträge und Änderungen eingereicht, die in die Ausarbeitung des finalen Textes einbezogen wurden.
- Am 14. Juni 2023 kam es dann zur großen Abstimmung im EU-Parlament. Mit 499 Ja-Stimmen, 28 Nein-Stimmen und 93 Enthaltungen wurde eine Verhandlungsposition zum AI-Gesetz angenommen.
- Am 09. Dezember 2023 erzielten Rat und Parlament dann eine vorläufige Einigung zum AI-Gesetz.
- Mit Beginn des Jahres 2024 wurde das Europäische Büro für künstliche Intelligenz innerhalb der Kommission eingerichtet und weitere Prozesse für die schrittweise Umsetzung und Ausgestaltung des EU AI Acts angestoßen. Ein vollständige Übersicht des zeitlichen Verlaufs des Gestaltungsprozesses und der damit verbundenen Institutionen und Zwischenstände finden Sie hier: https://artificialintelligenceact.eu/de/entwicklungen/.

> Initialer Push durch Parlament und Standardisierungsrequest
> Vier-Spalten-Dokument und Verhandlung zwischen Rat, Kommission und Parlament

## Vergleich mit anderen Ländern / Regionen

## insbesondere USA, Kanada und England

Betrachtet man den EU AI Act als groß angelegte Normierung innerhalb des europäischen Raums, drängt sich schnell die Frage auf, welche Auswirkungen die Gesetzgebung außerhalb seiner Mitgliedsstaaten haben wird. Es kann dabei davon ausgegangen werden, dass das EU-Parlament zwar primär die Regulierung im eigenen Legislaturbereich im Blick hat, aber auch auf andere große Volkswirtschaften wie die USA, China und das Vereinigte Königreich schaut, wenn es um den Einsatz von KI geht. Wie schon bei der Datenschutz-Grundverordnung (DSGVO) scheint hier der Gedanke zu sein, einen weitreichenden "Goldstandard" zu schaffen, der auch die Gesetzgebung in den Nationen außerhalb der EU bestimmt. Wir halten es deshalb für sinnvoll, einen kurzen Blick auf den aktuellen Stand der KI-Regulierung in anderen Nationen zu werfen, um diese Vorstellung besser einordnen zu können.

### Vereinigtes Königreich###

Schaut man dazu beispielsweise über den Kanal ins Vereinigte Königreich, so stellt man fest, dass auch dort weitreichende Maßnahmen für die Regulierung und den ethischen Umgang mit KI bereits getroffen worden sind. Die britische Regierung setzt dabei auf bestehende sektorale Vorgaben wie bspw. die KI-Prinzipien der OECD oder die Empfehlung zu ethischem Umgang mit KI der UNESCO. Diese übergeordneten Richtlinien werden durch lokal angetriebene Maßnahmen erweitert. Von besonderer Bedeutung ist dabei zum Beispiel die Bletchley Declaration aus November 2023, bei der sich 28 Länder, darunter die Vereinigten Staaten, China und die Europäische Union, geeinigt haben, international bei der Bewältigung von Herausforderungen und Risiken im Bereich der KI zusammenzuarbeiten. Im Fokus standen dabei vor allem "frontier"-Systeme, also KI-Grundlagenmodelle, die für alle möglichen Anwendungsfälle nutzbar gemacht werden können, so wie bspw. die ChatGPT zugrundeliegenden LLMs.  Es gibt also ein klares Bewusstsein für die Bedeutung des Themas KI und erste Bestrebungen für Lösungen. Die dabei getroffenen Vereinbarungen sind dabei eher Leitlinie und weniger strenges Regularium als es der EU AI Act sein möchte.

### USA###

Demgegenüber steht die Regulierung von KI in den USA derzeit noch am Anfang. Zwar sind auch diese Teil der Bletchley Declaration, trotzdem fehlt ein kohärentes nationales Regelwerk. Aktuell gibt es in den USA keine umfassende föderale KI-Regulierung, sondern lediglich fragmentierte Richtlinien und Bestrebungen auf Bundesstaatenebene und in verschiedenen Sektoren. Bundesbehörden wie die Federal Trade Commission (FTC) haben zwar Leitlinien zur Vermeidung unfairer oder irreführender KI-Anwendungen herausgegeben, aber umfassende gesetzliche Regelungen stehen noch aus.

Allerdings gibt es zunehmend Bestrebungen, eine konsistente Regulierung zu entwickeln. Präsident Joe Biden hat Anfang 2021 den "National Artificial Intelligence Initiative Act" unterzeichnet, der die Forschung und Entwicklung von KI koordiniert und fördert. Zudem hat das Weiße Haus Ende 2022 einen "Blueprint for an AI Bill of Rights" veröffentlicht, der Prinzipien zum Schutz der Bürgerrechte im Zusammenhang mit KI vorschlägt.

Während die EU mit dem AI Act einen klaren und strengen Regulierungsrahmen vorgibt, arbeiten die USA daran, ihre Strategie zu entwickeln, die wahrscheinlich stärker auf Selbstregulierung und sektorale Ansätze setzt, um Innovationen nicht zu behindern​ ([Pinsent Masons](https://www.pinsentmasons.com/out-law/news/eu-ai-act-takes-latest-step-through-european-parliament))​​ ([Skadden, Arps, Slate, Meagher & Flom LLP](https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation))​.

### Kanada###

Im Kontext des EU AI Acts hat Kanada ebenfalls Schritte unternommen, um den Einsatz von KI zu regulieren und zu fördern. Aktuell wird KI in Kanada hauptsächlich durch den **Artificial Intelligence and Data Act (AIDA)** reguliert, der Teil des umfassenden Digital Charter Implementation Acts ist, welcher im Juni 2022 vorgeschlagen wurde. AIDA zielt darauf ab, KI-Systeme zu regulieren, die ein erhebliches Risiko für die Sicherheit der Menschen oder ihre Grundrechte darstellen. Der Ansatz umfasst Verpflichtungen zur Transparenz, zur Risikobewertung und zur Einhaltung ethischer Standards.

Zusätzlich gibt es in Kanada Bestrebungen, die Regulierung weiter zu verfeinern und zu stärken. Die kanadische Regierung arbeitet daran, Richtlinien und Standards zu entwickeln, die sicherstellen, dass KI-Systeme sicher, fair und transparent sind. Dies beinhaltet auch die Zusammenarbeit mit internationalen Partnern und Organisationen, um globale Standards zu fördern und die Interoperabilität von Regulierungsrahmen zu gewährleisten.

Im Vergleich zum EU AI Act, der einen sehr strukturierten und strengen Rahmen vorgibt, verfolgt Kanada einen eher kooperativen und flexiblen Ansatz. Die kanadische Regulierung konzentriert sich auf die Förderung von Innovationen, während sie gleichzeitig sicherstellt, dass die Entwicklung und der Einsatz von KI ethisch und verantwortungsvoll erfolgen ([Pinsent Masons](https://www.pinsentmasons.com/out-law/news/eu-ai-act-takes-latest-step-through-european-parliament))​​ ([Skadden, Arps, Slate, Meagher & Flom LLP](https://www.skadden.com/insights/publications/2024/02/latest-text-of-eu-ai-act-proposes-expanding-obligation))​.

Zusammengefasst kann festgehalten werden, dass zwar viele Nicht-EU-Nationen eine klare Vorstellung von KI und potenziellen unkontrollierten Auswirkungen haben, im Gegensatz zur EU allerdings teilweise noch am Anfang einer konkreten Ausformulierung von Regeln und Gesetzen stehen oder generell einen offeneren Ansatz mit Blick auf möglichst freie Innovationsentwicklung verfolgen.

## Umsetzung des Acts in den Mitgliedstaaten##

Die faktische Umsetzung des EU AI Acts in den Mitgliedstaaten erfordert sorgfältige Planung und Koordination, um die umfassenden Anforderungen des Gesetzes zu erfüllen.

### Primäre Inhalte des EU AI Acts

Der EU AI Act ist ein umfassendes Regelwerk, das den Einsatz von KI innerhalb der EU reguliert. Zu den primären Inhalten gehören die Kategorisierung von KI-Systemen nach ihrem Risiko (unzulässiges, hohes, begrenztes und minimales Risiko), spezifische Anforderungen für Hochrisiko-Systeme, Transparenz- und Sicherheitsanforderungen sowie die Einrichtung eines EU-weiten Überwachungssystems für KI-Anwendungen. Einen tieferen Einblick in das Thema Risikoklassifizierung und Risikostufen finden Sie in den Kapiteln 02 und 03. Diese Maßnahmen zielen darauf ab, die Sicherheit, Transparenz und Verantwortung im Umgang mit KI zu gewährleisten und gleichzeitig Innovationen zu fördern. Darüber hinaus bilden sie eine feste rechtliche Grundlage, die Unternehmen, Forschung und Endnutzer:innen befähigt, rechtssicher mit KI umzugehen.

### Anwendungsbereich und betroffene Systeme

Der Act findet Anwendung bei verschiedenen KI-Systemen, abhängig von ihrem Risiko. Hochrisiko-Systeme umfassen beispielsweise KI-Anwendungen in kritischen Infrastrukturen, wie etwa KI-gesteuerte Systeme im Gesundheitswesen. Ein konkretes Beispiel wäre ein KI-gestütztes Diagnosetool in Krankenhäusern, das strengen Auflagen hinsichtlich Datenqualität, Transparenz und menschlicher Aufsicht unterliegt. Niedrigrisiko-Systeme, wie etwa Chatbots oder KI-basierte Spiele, unterliegen weniger strengen Regelungen, müssen aber dennoch gewisse Transparenzanforderungen erfüllen.

### Relevante Beteiligte

Alle Anbieter:innen und Nutzer:innen von KI-Systemen innerhalb der EU müssen sich mit den Anforderungen des Acts auseinandersetzen. Dies umfasst Entwickler:innen, Anbieter:innen und Anwender:innen von KI-Technologien. Privatpersonen, die KI-Anwendungen wie ChatGPT nutzen, sind in der Regel nicht direkt betroffen, solange sie diese nur als Endnutzer:innen einsetzen und die Anwendungen den regulatorischen Anforderungen entsprechen. Unternehmen, die solche Technologien entwickeln oder bereitstellen, müssen hingegen sicherstellen, dass ihre Produkte konform sind.

### Sanktionen bei Verstößen

Bei Verstößen gegen den EU AI Act drohen erhebliche Sanktionen. Die vorgeschlagenen Strafen umfassen Bußgelder von bis zu 35 Millionen Euro oder 7% des weltweiten Jahresumsatzes. Die faktische Umsetzung des EU AI Acts in den Mitgliedstaaten erfordert umfassende Maßnahmen zur Einhaltung der neuen Vorschriften, die eine sichere und transparente Nutzung von KI sicherstellen sollen.

## Fazit##

Zusammenfassend lässt sich sagen, dass der EU AI Act ein umfassendes und wegweisendes Regelwerk darstellt, das den Einsatz von KI in der EU regulieren soll. Er kategorisiert KI-Systeme nach ihrem Risikoniveau und legt spezifische Anforderungen für Hochrisiko-Systeme fest, um Sicherheit, Transparenz und Verantwortlichkeit zu gewährleisten. Der Act betrifft eine Vielzahl von KI-Anwendungen, von Gesundheitsdiagnosetools bis hin zu Chatbots, und erfordert von Anbieter:innen und Nutzer:innen die Einhaltung strenger Vorgaben. Bei Verstößen drohen erhebliche Sanktionen, einschließlich hoher Bußgelder. In den nächsten Modulen werden wir uns detailliert mit den Risikostufen und der Klassifizierung von KI-Systemen befassen, um ein tieferes Verständnis für die Implementierung und Einhaltung des EU AI Acts zu entwickeln.

- Primäre Inhalte des Acts
- Auf was trifft das zu? Welche Systeme sind davon betroffen?
- Wer muss sich darum Gedanken machen? Darf ich kein ChatGPT mehr benutzen?
- Was ist, wenn man dagegen verstößt?


+ Wie geht es weiter?

https://artificialintelligenceact.eu/standard-setting/

https://iapp.org/media/pdf/resource_center/global_ai_legislation_tracker.pdf

https://www.chathamhouse.org/2024/03/eus-new-ai-act-could-have-global-impact