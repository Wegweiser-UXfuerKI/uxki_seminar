# Grundlagen UX und Usability

## Risikostufen

**Minimales Risiko**: Diese Kategorie umfasst KI-Systeme, bei denen das Risiko für die menschliche Sicherheit oder grundlegende Rechte als gering oder vernachlässigbar eingestuft wird. Ein Beispiel dafür ist ein KI-System, das zur automatischen Sortierung von E-Mails verwendet wird, um Spam von legitimen Nachrichten zu trennen. Das Risiko für die menschliche Sicherheit ist minimal, da die Auswirkungen von Fehlklassifikationen gering sind.  
**Limitiertes Risiko**: Hierbei handelt es sich um KI-Systeme, bei denen klar festgelegt ist, wie und unter welchen Umständen sie eingesetzt werden dürfen, um potenzielle Risiken zu begrenzen. Das gilt z.B. beim Einsatz von Chatbots, die nur bei einfachen Anfragen eingesetzt wird. Es ist klar festgelegt, dass sie nur grundlegende Fragen beantworten können und bei komplexen Problemen an einen menschlichen Vertreter weiterleiten.  
**Hoch-Risiko-Systeme**: Diese Stufe betrifft KI-Anwendungen, die ein erhöhtes Risiko für Menschenrechte, Sicherheit oder gesellschaftliche Werte darstellen. Sie erfordern umfassende Dokumentation von Training, Modell und Designentscheidungen sowie eine Betonung von Transparenz und menschlicher Kontrolle. In diese Kategorie gehören medizinische Systeme, Systeme im Bereich der Strafverfolgung oder auch Systeme, die zur politischen Meinungsbildung geeignet sind. Ein Beispiel ist ein autonomes Fahrzeug, das ohne menschliches Eingreifen auf öffentlichen Straßen fährt.  
**Inakzeptables Risiko**: KI-Anwendungen, die ein unannehmbares Risiko für grundlegende Menschenrechte oder die physische Sicherheit darstellen, sind strengstens verboten. Darunter fallen alle Systeme, die für Menschen und unsere demokratischen Werte gefährlich sein können bspw. Social Scoring Systeme, Deep Fake Tools oder Profiling-Systeme.

## Designimplikationen

Zusätzlich legt der EUAI-Act bestimmte Designimplikationen für KI-Systeme fest:

**Klarstellung der Interaktion mit KI-Systemen**: Nutzer müssen deutlich darüber informiert werden, dass sie mit automatisierten Systemen interagieren.  
**Bereitstellung von Informationen**: Es müssen Informationen über die Funktionsweise und den Zweck von KI-Systemen bereitgestellt werden, um Transparenz zu gewährleisten.  
**Hohe menschliche Kontrollfähigkeit**: Die Möglichkeit für Menschen, die Kontrolle über KI-Systeme zu behalten, muss gewährleistet sein, damit Entscheidungen nachvollzogen und gegebenenfalls korrigiert werden können.  
**Nachvollziehbare Erklärungen**: Es müssen nachvollziehbare Erklärungen für Entscheidungen oder Handlungen von KI-Systemen bereitgestellt werden, um Vertrauen und Akzeptanz zu fördern.  
**Verhinderung ungewollter Beeinflussung**: Mechanismen müssen implementiert werden, um ungewollte oder unbewusste Beeinflussung durch KI-Systeme zu verhindern und potenzielle Schäden zu minimieren.
